{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Sentiment140.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MMWlNLctMJR",
        "outputId": "c6d66be6-d178-4add-fdd3-01f8c44a2649"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"data/sentiment140-subset.csv\", nrows=100000)\n",
        "df = df.drop(index=90) #this tweet's formatting is just really messed up\n",
        "df.head(100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>polarity</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@kconsidder You never tweet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Sick today  coding from the couch.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>@ChargerJenn Thx for answering so quick,I was ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Wii fit says I've lost 10 pounds since last ti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>@MrKinetik Not a thing!!!  I don't really have...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>and its pretty cool  I never thought I would e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>finallly! twitter wouldnt let me in!    x</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>Just took a shower, i feel so refreshed now</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>Love the show! You and Jasmine got me watching...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>I have a story to tell you... its my birthday ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>That came out wrong. I heart @danielradcliffe ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>Just got done with the Fam celebratin Jun bday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>dissapointed about missing the VIP chance on N...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>@i_am_girlfriday aw, i'm sure you were absolut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>@Jefner Thanks for the welcome  I hope it does...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>@iamdiddy I'm here for diddy!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>Fact #1: Between 70-75% of bottled water comes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>Going to bed now. not gonna wait longer, if th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>ohhhhhh im so ready for a relaxing weekend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>http://www.flickr.com/people/bugekgek/ Thy new...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0</td>\n",
              "      <td>is up to no good.  has to leave for camping in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0</td>\n",
              "      <td>@SaintBastard dude. I'm a Caps fan at heart. 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1</td>\n",
              "      <td>happy birthday mother</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1</td>\n",
              "      <td>@Edwin808 there u go u see RE and Bodysnatchin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1</td>\n",
              "      <td>@mrsjackbauer7 haha omg it works now... finally!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0</td>\n",
              "      <td>About to spend an evening of unadulterated gam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0</td>\n",
              "      <td>I wanted to go eat with you guys but my mom ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0</td>\n",
              "      <td>@dirty69_4ever my wife and I need 2 get to bed...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>1</td>\n",
              "      <td>. @MaryRSnyder Thank you!  I figured you could...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0</td>\n",
              "      <td>@chanicedev0nne wtf niecey  r u serious.. dam ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>0</td>\n",
              "      <td>The Show is Over  But Auditiong for Army Wives...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>1</td>\n",
              "      <td>@gutuh Vi FRIENDS e agora estÃ¡ comeÃ§ando The...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>0</td>\n",
              "      <td>@charlestlee too long for an rt.  Think you ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>0</td>\n",
              "      <td>@amandapalmer Yay for t-shirt! Am unhappy i mi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>0</td>\n",
              "      <td>I'm just about ready for falling asleep.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>0</td>\n",
              "      <td>@DelightDevine how was miss winona? sorry i di...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>1</td>\n",
              "      <td>@karenmorris By nodding, I presume you mean in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>0</td>\n",
              "      <td>is frustrated. jeremy last is leaving twitter....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>0</td>\n",
              "      <td>@jonskeeetskeeet Dude Tylenol is ineffective w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>1</td>\n",
              "      <td>Waiting to watch season 7 of The Shield its go...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>0</td>\n",
              "      <td>Studying for finals. I hate school. A lot. But...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>0</td>\n",
              "      <td>last foster's are coming on tonight.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>0</td>\n",
              "      <td>miss u sis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>0</td>\n",
              "      <td>should be leaving for indy right about now, bu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>0</td>\n",
              "      <td>@lauryqui  we're gonna miss you. dont worry, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>0</td>\n",
              "      <td>Uggghhhh allotropes, nanoparticles and buckmin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>1</td>\n",
              "      <td>@MunkeeZero I love that song.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>1</td>\n",
              "      <td>@captainnathanj: Hahah!  That's awesome.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>0</td>\n",
              "      <td>I'm sick, and I stayed at home today too ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>1</td>\n",
              "      <td>I updated my livejournal! check it out here!  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>1</td>\n",
              "      <td>Work tomorrow,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>0</td>\n",
              "      <td>going out of town next week until the whole mo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>0</td>\n",
              "      <td>false alarm guys.  i found out I work the WORS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>0</td>\n",
              "      <td>@30yearoldtwifan HMM.... well thinking like sh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0</td>\n",
              "      <td>*(^#*^*($^)*&amp;amp;&amp;amp;((@&amp;amp;&amp;amp;^&amp;amp; Car ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0</td>\n",
              "      <td>Another late night with no sleep in sight... p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0</td>\n",
              "      <td>Aw, my tattoo is buring like a motherfucker ug...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>1</td>\n",
              "      <td>@aTexasAttitude I completely agree, no amount ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>1</td>\n",
              "      <td>Is Going Chingford 2 C Auntie And Get Some Jeg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>1</td>\n",
              "      <td>LOL... I just realized how this works! No i ha...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     polarity                                               text\n",
              "0           0                      @kconsidder You never tweet  \n",
              "1           0                 Sick today  coding from the couch.\n",
              "2           1  @ChargerJenn Thx for answering so quick,I was ...\n",
              "3           1  Wii fit says I've lost 10 pounds since last ti...\n",
              "4           0  @MrKinetik Not a thing!!!  I don't really have...\n",
              "5           1  and its pretty cool  I never thought I would e...\n",
              "6           0          finallly! twitter wouldnt let me in!    x\n",
              "7           1       Just took a shower, i feel so refreshed now \n",
              "8           0  Love the show! You and Jasmine got me watching...\n",
              "9           1  I have a story to tell you... its my birthday ...\n",
              "10          1  That came out wrong. I heart @danielradcliffe ...\n",
              "11          0  Just got done with the Fam celebratin Jun bday...\n",
              "12          0  dissapointed about missing the VIP chance on N...\n",
              "13          1  @i_am_girlfriday aw, i'm sure you were absolut...\n",
              "14          1  @Jefner Thanks for the welcome  I hope it does...\n",
              "15          1                     @iamdiddy I'm here for diddy! \n",
              "16          1  Fact #1: Between 70-75% of bottled water comes...\n",
              "17          0  Going to bed now. not gonna wait longer, if th...\n",
              "18          1        ohhhhhh im so ready for a relaxing weekend \n",
              "19          1  http://www.flickr.com/people/bugekgek/ Thy new...\n",
              "20          0  is up to no good.  has to leave for camping in...\n",
              "21          0  @SaintBastard dude. I'm a Caps fan at heart. 0...\n",
              "22          1                             happy birthday mother \n",
              "23          1  @Edwin808 there u go u see RE and Bodysnatchin...\n",
              "24          1  @mrsjackbauer7 haha omg it works now... finally! \n",
              "25          0  About to spend an evening of unadulterated gam...\n",
              "26          0  I wanted to go eat with you guys but my mom ma...\n",
              "27          0  @dirty69_4ever my wife and I need 2 get to bed...\n",
              "28          1  . @MaryRSnyder Thank you!  I figured you could...\n",
              "29          0  @chanicedev0nne wtf niecey  r u serious.. dam ...\n",
              "..        ...                                                ...\n",
              "70          0  The Show is Over  But Auditiong for Army Wives...\n",
              "71          1  @gutuh Vi FRIENDS e agora estÃ¡ comeÃ§ando The...\n",
              "72          0  @charlestlee too long for an rt.  Think you ca...\n",
              "73          0  @amandapalmer Yay for t-shirt! Am unhappy i mi...\n",
              "74          0          I'm just about ready for falling asleep. \n",
              "75          0  @DelightDevine how was miss winona? sorry i di...\n",
              "76          1  @karenmorris By nodding, I presume you mean in...\n",
              "77          0  is frustrated. jeremy last is leaving twitter....\n",
              "78          0  @jonskeeetskeeet Dude Tylenol is ineffective w...\n",
              "79          1  Waiting to watch season 7 of The Shield its go...\n",
              "80          0  Studying for finals. I hate school. A lot. But...\n",
              "81          0             last foster's are coming on tonight.  \n",
              "82          0                                        miss u sis \n",
              "83          0  should be leaving for indy right about now, bu...\n",
              "84          0  @lauryqui  we're gonna miss you. dont worry, t...\n",
              "85          0  Uggghhhh allotropes, nanoparticles and buckmin...\n",
              "86          1                     @MunkeeZero I love that song. \n",
              "87          1           @captainnathanj: Hahah!  That's awesome.\n",
              "88          0      I'm sick, and I stayed at home today too ... \n",
              "89          1  I updated my livejournal! check it out here!  ...\n",
              "91          1                                    Work tomorrow, \n",
              "92          0  going out of town next week until the whole mo...\n",
              "93          0  false alarm guys.  i found out I work the WORS...\n",
              "94          0  @30yearoldtwifan HMM.... well thinking like sh...\n",
              "95          0  *(^#*^*($^)*&amp;&amp;((@&amp;&amp;^&amp; Car ...\n",
              "96          0  Another late night with no sleep in sight... p...\n",
              "97          0  Aw, my tattoo is buring like a motherfucker ug...\n",
              "98          1  @aTexasAttitude I completely agree, no amount ...\n",
              "99          1  Is Going Chingford 2 C Auntie And Get Some Jeg...\n",
              "100         1  LOL... I just realized how this works! No i ha...\n",
              "\n",
              "[100 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lk1XptFtMJZ"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkJOtQdgtMJa"
      },
      "source": [
        "import re\n",
        "import string\n",
        "import unidecode\n",
        "\n",
        "def remove_punct(s):\n",
        "    punct = string.punctuation + 'Ã§º¯³|¡¿'\n",
        "    for char in punct:\n",
        "        s = s.replace(char, '')\n",
        "    return s\n",
        "\n",
        "def remove_accents(accented_string):\n",
        "    unaccented_string = unidecode.unidecode(accented_string)\n",
        "    return unaccented_string\n",
        "\n",
        "def clean(df):\n",
        "    df['text'] = df['text'].map(lambda x:re.sub(r'\\w*@\\w*', '', x) ) #remove twitter handles\n",
        "    df['text'] = df['text'].map(lambda x:re.sub(r'http\\S+', '', x) ) #remove urls\n",
        "    df['text'] = df['text'].map(lambda x:re.sub(r'[0-9]', '', x) ) #remove numbers\n",
        "    df['text'] = df['text'].map(lambda x:remove_punct(x)) #remove punctuation marks\n",
        "    df['text'] = df['text'].map(lambda x:remove_accents(x)) #remove accents\n",
        "    df['text'] = df['text'].map(lambda x: x.lower()) #lower case\n",
        "    \n",
        "    \n",
        "    \n",
        "#     df['text'] = df['text'].map(lambda x:re.sub(r'\\w*¿½\\w*', '', x) )\n",
        "#     df['text'] = df['text'].map(lambda x:re.sub(r'&amp*', '', x) )\n",
        "\n",
        "clean(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZr84o5StMJa"
      },
      "source": [
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "vectors = vectorizer.fit_transform(df.text)\n",
        "words_df = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names())\n",
        "words_df.head()\n",
        "\n",
        "results = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11uDLNq5tMJb"
      },
      "source": [
        "y = df.polarity #sentiments\n",
        "X = words_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vX1uXHJ0tMJb"
      },
      "source": [
        "### Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9WdchOWtMJb"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.gaussian_process import ne\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJUjo9XktMJc"
      },
      "source": [
        "#### Log Reg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL7rCqqutMJc",
        "outputId": "12978caf-4b07-4802-9b1f-0c92a542618c"
      },
      "source": [
        "%%time\n",
        "\n",
        "clf = GridSearchCV(estimator=LogisticRegression(solver='newton-cg'), param_grid={\n",
        "        }, cv=10\n",
        "      )\n",
        "\n",
        "clf.fit(X, y)\n",
        "clf_df = pd.DataFrame(clf.cv_results_)\n",
        "clf_df\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wall time: 2min 38s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split3_test_score</th>\n",
              "      <th>split4_test_score</th>\n",
              "      <th>split5_test_score</th>\n",
              "      <th>split6_test_score</th>\n",
              "      <th>split7_test_score</th>\n",
              "      <th>split8_test_score</th>\n",
              "      <th>split9_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.13958</td>\n",
              "      <td>0.492632</td>\n",
              "      <td>0.022261</td>\n",
              "      <td>0.001734</td>\n",
              "      <td>{}</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.7628</td>\n",
              "      <td>0.7612</td>\n",
              "      <td>0.768</td>\n",
              "      <td>0.7634</td>\n",
              "      <td>0.7612</td>\n",
              "      <td>0.7584</td>\n",
              "      <td>0.7556</td>\n",
              "      <td>0.7605</td>\n",
              "      <td>0.766477</td>\n",
              "      <td>0.761758</td>\n",
              "      <td>0.003457</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  mean_score_time  std_score_time params  \\\n",
              "0       14.13958      0.492632         0.022261        0.001734     {}   \n",
              "\n",
              "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
              "0               0.76             0.7628             0.7612              0.768   \n",
              "\n",
              "   split4_test_score  split5_test_score  split6_test_score  split7_test_score  \\\n",
              "0             0.7634             0.7612             0.7584             0.7556   \n",
              "\n",
              "   split8_test_score  split9_test_score  mean_test_score  std_test_score  \\\n",
              "0             0.7605           0.766477         0.761758        0.003457   \n",
              "\n",
              "   rank_test_score  \n",
              "0                1  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8A53gQ-ItMJc"
      },
      "source": [
        "results[clf.best_score_] = ['LogsiticRegression', clf.best_params_]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OY9Md8ortMJd",
        "outputId": "7d32ee2c-69a7-4cdc-aa03-9d49ab44514f"
      },
      "source": [
        "results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0.7617576647664767: ['LogsiticRegression', {}]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hpf9mu6ktMJd"
      },
      "source": [
        "#### Lin Reg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pa-LYut0tMJd",
        "outputId": "5d3c578f-8bd6-4ed7-d15a-9f26b3b9c6b4"
      },
      "source": [
        "%%time\n",
        "\n",
        "clf = GridSearchCV(estimator=LinearRegression(), param_grid={\n",
        "        'normalize': (True, False),\n",
        "        }, cv=10\n",
        "      )\n",
        "clf.fit(X, y)\n",
        "clf_df = pd.DataFrame(clf.cv_results_)\n",
        "# clf_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wall time: 33.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "men8u4q4tMJe"
      },
      "source": [
        "results[clf.best_score_] = ['LinearRegression', clf.best_params_]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjQ-io1utMJf",
        "outputId": "c4cae843-9c1c-4f6e-f99f-b5470fda9c28"
      },
      "source": [
        "results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0.7551583750138936: ['LogsiticRegression', {'solver': 'newton-cg'}],\n",
              " 0.3084938169917256: ['LinearRegression', {'normalize': True}]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVuIiJy_tMJg"
      },
      "source": [
        "#### Linear SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu2K14G2tMJg",
        "outputId": "34048dba-d02c-4586-fc9c-66ef15d5da77"
      },
      "source": [
        "%%time\n",
        "\n",
        "clf = GridSearchCV(estimator=LinearSVC(loss='squared_hinge'), param_grid={\n",
        "        'max_iter': (5000, 10000, 50000),\n",
        "        'dual': (True, False),\n",
        "        }, cv=10\n",
        "      )\n",
        "clf.fit(X, y)\n",
        "clf_df = pd.DataFrame(clf.cv_results_)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wall time: 22.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb92x6B3tMJg"
      },
      "source": [
        "results[clf.best_score_] = ['LinearSVC', clf.best_params_]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVarAvGztMJh",
        "outputId": "2ebbe7e7-1b9a-40ab-fc6b-f2f3dcce60e4"
      },
      "source": [
        "results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0.7551583750138936: ['LogsiticRegression', {'solver': 'newton-cg'}],\n",
              " 0.3084938169917256: ['LinearRegression', {'normalize': True}],\n",
              " 0.7523916638879626: ['LinearSVC', {'dual': True, 'max_iter': 5000}]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__OpLn17tMJh"
      },
      "source": [
        "#### Multinomial Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2y-rkIAItMJh",
        "outputId": "02a6e20f-86df-4c71-a04b-16865e99e293"
      },
      "source": [
        "%%time\n",
        "\n",
        "clf = GridSearchCV(estimator=MultinomialNB(), param_grid={\n",
        "        'alpha': (0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5, 9.0, 9.5, 10.0)\n",
        "        }, cv=10\n",
        "      )\n",
        "clf.fit(X, y)\n",
        "clf_df = pd.DataFrame(clf.cv_results_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wall time: 40.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4r-_p6PjtMJi"
      },
      "source": [
        "results[clf.best_score_] = ['MultinomialNB', clf.best_params_]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCf5nYvBtMJi",
        "outputId": "ab0de195-70e2-4683-dca4-fdda5c7acc80"
      },
      "source": [
        "results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0.7551583750138936: ['LogsiticRegression', {'solver': 'newton-cg'}],\n",
              " 0.3084938169917256: ['LinearRegression', {'normalize': True}],\n",
              " 0.7523916638879626: ['LinearSVC', {'dual': True, 'max_iter': 5000}],\n",
              " 0.746458241636101: ['MultinomialNB', {'alpha': 6.5}]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "350lH--ztMJi"
      },
      "source": [
        "#### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9lVvqhctMJi",
        "outputId": "55dff705-b58a-4418-bb55-f2f2fe601fe2"
      },
      "source": [
        "%%time\n",
        "\n",
        "clf = GridSearchCV(estimator=RandomForestClassifier(), param_grid={\n",
        "        'n_estimators': (10, 100, 150),\n",
        "        }, cv=10\n",
        "      )\n",
        "clf.fit(X, y)\n",
        "clf_df = pd.DataFrame(clf.cv_results_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wall time: 25min 50s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDsPT6-dtMJj"
      },
      "source": [
        "results[clf.best_score_] = ['RandomForest', clf.best_params_]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0uhJ8PotMJj",
        "outputId": "95032f8c-94df-40f3-c883-c7707c63d002"
      },
      "source": [
        "results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0.7551583750138936: ['LogsiticRegression', {'solver': 'newton-cg'}],\n",
              " 0.3084938169917256: ['LinearRegression', {'normalize': True}],\n",
              " 0.7523916638879626: ['LinearSVC', {'dual': True, 'max_iter': 5000}],\n",
              " 0.746458241636101: ['MultinomialNB', {'alpha': 6.5}],\n",
              " 0.7402913193286651: ['RandomForest', {'n_estimators': 150}]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_s3NmWytMJj"
      },
      "source": [
        "#### AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD9qNa14tMJj",
        "outputId": "140cca72-ac2b-4177-82a7-7b6903921412"
      },
      "source": [
        "%%time\n",
        "\n",
        "clf = GridSearchCV(estimator=AdaBoostClassifier(), param_grid={\n",
        "        'learning_rate': (1.0, 2.0, 3.0),\n",
        "        }, cv=10\n",
        "      )\n",
        "clf.fit(X, y)\n",
        "clf_df = pd.DataFrame(clf.cv_results_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wall time: 14min 54s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQQJPD6ztMJj"
      },
      "source": [
        "results[clf.best_score_] = ['AdaBoost', clf.best_params_]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YKHK2RotMJk",
        "outputId": "28a39bd1-5e0c-4d00-f342-7f05e5413725"
      },
      "source": [
        "results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0.7551583750138936: ['LogsiticRegression', {'solver': 'newton-cg'}],\n",
              " 0.3084938169917256: ['LinearRegression', {'normalize': True}],\n",
              " 0.7523916638879626: ['LinearSVC', {'dual': True, 'max_iter': 5000}],\n",
              " 0.746458241636101: ['MultinomialNB', {'alpha': 6.5}],\n",
              " 0.7402913193286651: ['RandomForest', {'n_estimators': 150}],\n",
              " 0.6860564632655329: ['AdaBoost', {'learning_rate': 1.0}]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZPZBgCftMJk"
      },
      "source": [
        "#### Gaussian Process Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Edx76LJotMJk"
      },
      "source": [
        "#this one doesn't work"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "G3w4F4lQtMJk"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5B8mjh3tMJk"
      },
      "source": [
        "### Using BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jgj-TcNhtMJl"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"data/sentiment140-subset.csv\", nrows=30000)\n",
        "df = df.drop(index=90) #this tweet's formatting is just really messed up"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cjX1B7ftMJl"
      },
      "source": [
        "clean(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xxvPN4HtMJl"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import transformers as ppb\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kmQ9YsHtMJm"
      },
      "source": [
        "# For DistilBERT:\n",
        "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "\n",
        "## Want BERT instead of distilBERT? Uncomment the following line:\n",
        "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
        "\n",
        "# Load pretrained model/tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "model = model_class.from_pretrained(pretrained_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-4e18IutMJm",
        "outputId": "4d0dc1d2-4470-4031-d7cd-68ea7f221b1a"
      },
      "source": [
        "tokenized = df['text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "global_max_len = len(tokenized.values[0])\n",
        "for li in tokenized.values:\n",
        "    global_max_len = max(global_max_len, len(li))\n",
        "print(global_max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "86\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bV1s1zoqtMJn"
      },
      "source": [
        "num_batches = 20\n",
        "\n",
        "batch_1, batch_2, batch_3, batch_4, batch_5, batch_6, batch_7, batch_8, batch_9, batch_10, batch_11, batch_12, batch_13, batch_14, batch_15, batch_16, batch_17, batch_18, batch_19, batch_20 = np.array_split(df, num_batches)\n",
        "\n",
        "batches = [batch_1, batch_2, batch_3, batch_4, batch_5, batch_6, batch_7, batch_8, batch_9, batch_10, batch_11, batch_12, batch_13, batch_14, batch_15, batch_16, batch_17, batch_18, batch_19, batch_20]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKuHP_eStMJn",
        "outputId": "bf3afc30-e393-4054-e603-6de2fe5a8255"
      },
      "source": [
        "#this is tokenizing the tweets and encoding them so that BERT can understand\n",
        "\n",
        "for batch in batches:\n",
        "    tokenized = batch['text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "    #add padding\n",
        "\n",
        "    max_len = len(tokenized.values[0])\n",
        "    for li in tokenized.values:\n",
        "        max_len = max(max_len, len(li))\n",
        "\n",
        "    padded = np.array([li + [0]*(max_len-len(li)) for li in tokenized.values])\n",
        "    \n",
        "    #masking\n",
        "    attention_mask = np.where(padded != 0, 1, 0)\n",
        "    \n",
        "    input_ids = torch.tensor(padded)  \n",
        "    attention_mask = torch.tensor(attention_mask)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
        "    features = last_hidden_states[0][:,0,:].numpy()\n",
        "    print(features)\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:75] data. DefaultCPUAllocator: not enough memory: you tried to allocate 251904000 bytes. Buy new RAM!",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-66-0df8268b92d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mlast_hidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlast_hidden_states\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    485\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m             \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m         )\n\u001b[0;32m    489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m             layer_outputs = layer_module(\n\u001b[1;32m--> 307\u001b[1;33m                 \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m             )\n\u001b[0;32m    309\u001b[0m             \u001b[0mhidden_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    252\u001b[0m             \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m         )\n\u001b[0;32m    256\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, query, key, value, mask, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv_lin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (bs, n_heads, k_length, dim_per_head)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m         \u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mq\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim_per_head\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (bs, n_heads, q_length, dim_per_head)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (bs, n_heads, q_length, k_length)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask_reshp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (bs, n_heads, q_length, k_length)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:75] data. DefaultCPUAllocator: not enough memory: you tried to allocate 251904000 bytes. Buy new RAM!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SQMQuqstMJo"
      },
      "source": [
        "batch = df[:1500]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3bBPmOttMJo",
        "outputId": "5f788a41-726a-40a2-de06-5c07449c0baf"
      },
      "source": [
        "\n",
        "tokenized = batch['text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "#add padding\n",
        "\n",
        "max_len = len(tokenized.values[0])\n",
        "for li in tokenized.values:\n",
        "    max_len = max(max_len, len(li))\n",
        "\n",
        "padded = np.array([li + [0]*(max_len-len(li)) for li in tokenized.values])\n",
        "\n",
        "#masking\n",
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "\n",
        "input_ids = torch.tensor(padded)  \n",
        "attention_mask = torch.tensor(attention_mask)\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
        "features = last_hidden_states[0][:,0,:].numpy()\n",
        "print(features)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.08996668  0.00164525 -0.08337827 ... -0.08960109  0.27462918\n",
            "   0.30040133]\n",
            " [-0.04538557 -0.00406603  0.07527261 ... -0.17595594  0.39300975\n",
            "   0.17493433]\n",
            " [ 0.14887248  0.07762916 -0.0452455  ... -0.10213505  0.400743\n",
            "   0.37653345]\n",
            " ...\n",
            " [ 0.07920368  0.4093396   0.18753985 ...  0.05454692  0.2608588\n",
            "   0.30745062]\n",
            " [-0.00567827 -0.06137022  0.08889808 ... -0.1516546   0.2996365\n",
            "   0.11575194]\n",
            " [-0.15403602 -0.04427864  0.25128025 ... -0.14146762  0.59053\n",
            "   0.0090637 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoVZy6URtMJo"
      },
      "source": [
        "labels = batch['text']\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T-TYicCtMJp",
        "outputId": "92b82fbb-857a-4465-a013-030e85012f47"
      },
      "source": [
        "# clf = LinearSVC(loss='squared_hinge')\n",
        "clf = LogisticRegression(solver='newton-cg')\n",
        "clf.fit(train_features, train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\rahul\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "C:\\Users\\rahul\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(solver='newton-cg')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrrQEOMrtMJp",
        "outputId": "78d004b0-83a3-4cdf-81b8-07631522198d"
      },
      "source": [
        "clf.score(test_features, test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0026666666666666666"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP14YmDvtMJq"
      },
      "source": [
        "#### Ready for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtqTZtkatMJq",
        "outputId": "53f34a7b-d386-479e-d92b-5904fcb5902a"
      },
      "source": [
        "input_ids = torch.tensor(padded)  \n",
        "attention_mask = torch.tensor(attention_mask)\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:75] data. DefaultCPUAllocator: not enough memory: you tried to allocate 15666677760 bytes. Buy new RAM!",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-53-592737a6eacd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mlast_hidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 480\u001b[1;33m             \u001b[0minputs_embeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (bs, seq_length, dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    481\u001b[0m         return self.transformer(\n\u001b[0;32m    482\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_embeddings\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mposition_embeddings\u001b[0m  \u001b[1;31m# (bs, max_seq_length, dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (bs, max_seq_length, dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (bs, max_seq_length, dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\normalization.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         return F.layer_norm(\n\u001b[1;32m--> 171\u001b[1;33m             input, self.normalized_shape, self.weight, self.bias, self.eps)\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[1;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[0;32m   2200\u001b[0m             \u001b[0mlayer_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2201\u001b[0m         )\n\u001b[1;32m-> 2202\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:75] data. DefaultCPUAllocator: not enough memory: you tried to allocate 15666677760 bytes. Buy new RAM!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pVpjZTStMJr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}